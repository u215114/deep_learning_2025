{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD31SqFZIzsL"
      },
      "source": [
        "# Drive & paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrCJJhEKEQDi"
      },
      "outputs": [],
      "source": [
        "data_path = 'raindrop_data'\n",
        "results_path = 'results'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u4gSMrWJLqF"
      },
      "source": [
        "# Imports or other fuctions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Tq6lsI_XJRXm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-ngfdUaAp7S"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UNaSO41AWt9",
        "outputId": "2665eed2-8497-4554-d13f-b162524503d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data image shape: torch.Size([3, 480, 720])\n",
            "GT image shape: torch.Size([3, 480, 720])\n"
          ]
        }
      ],
      "source": [
        "class RaindropDataset(Dataset):\n",
        "    def __init__(self, root_dir, mode='train', transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.mode = mode\n",
        "        self.transform = transform\n",
        "        self.image_dir = os.path.join(root_dir, mode, mode, \"data\")\n",
        "        self.clean_dir = os.path.join(root_dir, mode, mode, \"gt\")\n",
        "\n",
        "        self.rainy_images = sorted(os.listdir(self.image_dir))\n",
        "        self.clean_images = sorted(os.listdir(self.clean_dir))  # must match rain order!\n",
        "\n",
        "        assert len(self.rainy_images) == len(self.clean_images), \"Rainy and clean image count mismatch!\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.rainy_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        rain_path = os.path.join(self.image_dir, self.rainy_images[idx])\n",
        "        clean_path = os.path.join(self.clean_dir, self.clean_images[idx])\n",
        "\n",
        "        rain_img = Image.open(rain_path).convert(\"RGB\")\n",
        "        clean_img = Image.open(clean_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            rain_img = self.transform(rain_img)\n",
        "            clean_img = self.transform(clean_img)\n",
        "\n",
        "        return {'data': rain_img, 'gt': clean_img}\n",
        "\n",
        "# Define transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((480, 720)),  # Maintain your 720x480 resolution\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Create dataset instances\n",
        "train_dataset = RaindropDataset(root_dir=data_path,\n",
        "                              mode='train',\n",
        "                              transform=transform)\n",
        "\n",
        "test_a_dataset = RaindropDataset(root_dir=data_path,\n",
        "                                mode='test_a',\n",
        "                                transform=transform)\n",
        "\n",
        "test_b_dataset = RaindropDataset(root_dir=data_path,\n",
        "                                mode='test_b',\n",
        "                                transform=transform)\n",
        "\n",
        "# Example of accessing a sample\n",
        "sample = train_dataset[0]\n",
        "print(\"Data image shape:\", sample['data'].shape)\n",
        "print(\"GT image shape:\", sample['gt'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "Tes3UMHOF2FJ",
        "outputId": "3692b5c7-fec2-4274-9d01-3c291723b3fd"
      },
      "outputs": [],
      "source": [
        "# prompt: show one of the images of the train dataset (rain and clean)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get a sample from the training dataset\n",
        "sample = train_dataset[0]\n",
        "\n",
        "# Get the rain and clean images\n",
        "rain_image_tensor = sample['data']\n",
        "clean_image_tensor = sample['gt']\n",
        "\n",
        "# Convert tensors to numpy arrays for displaying\n",
        "# PyTorch tensors are (C, H, W), matplotlib expects (H, W, C) for color images\n",
        "rain_image_np = rain_image_tensor.permute(1, 2, 0).numpy()\n",
        "clean_image_np = clean_image_tensor.permute(1, 2, 0).numpy()\n",
        "\n",
        "# Display the images\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(rain_image_np)\n",
        "plt.title(\"Rainy Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(clean_image_np)\n",
        "plt.title(\"Clean Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJN-8yWVDM6y"
      },
      "source": [
        "# Fist Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyZWFbPFDgi4"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYQhJ3hWDX2n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Convolution + BatchNormalization + ReLU block for the encoder\n",
        "class ConvBNReLU(nn.Module):\n",
        "  \"\"\"\n",
        "  A block consisting of a Convolutional layer, Batch Normalization, and ReLU activation.\n",
        "\n",
        "  Args:\n",
        "      in_channels (int): Number of input channels.\n",
        "      out_channels (int): Number of output channels.\n",
        "      pooling (bool): If True, applies average pooling.\n",
        "  \"\"\"\n",
        "  def __init__(self, in_channels: int, out_channels: int, pooling: bool = False):\n",
        "      super(ConvBNReLU, self).__init__()\n",
        "      self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "      self.bn = nn.BatchNorm2d(out_channels)\n",
        "      self.relu = nn.ReLU(inplace=True)\n",
        "      self.pool = nn.AvgPool2d(2, 2) if pooling else None\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "      \"\"\"\n",
        "      Forward pass of the ConvBNReLU block.\n",
        "\n",
        "      Args:\n",
        "          x (torch.Tensor): Input tensor.\n",
        "\n",
        "      Returns:\n",
        "          torch.Tensor: Output tensor after applying Conv -> BN -> ReLU -> (optional) Pooling.\n",
        "      \"\"\"\n",
        "      if self.pool:\n",
        "          x = self.pool(x)\n",
        "      x = self.conv(x)\n",
        "      x = self.bn(x)\n",
        "      x = self.relu(x)\n",
        "      return x\n",
        "\n",
        "# BatchNormalization + ReLU block + Convolution for the decoder\n",
        "class BNReLUConv(nn.Module):\n",
        "  def __init__(self, in_channels: int, out_channels: int, upsampling: bool = False):\n",
        "      super(BNReLUConv, self).__init__()\n",
        "      self.bn = nn.BatchNorm2d(in_channels)\n",
        "      self.relu = nn.ReLU(inplace=True)\n",
        "      self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "      self.upsample = nn.Upsample(scale_factor=2, mode='nearest') if upsampling else None\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "      x = self.bn(x)\n",
        "      x = self.relu(x)\n",
        "      if self.upsample:\n",
        "          x = self.upsample(x)\n",
        "      x = self.conv(x)\n",
        "      return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "  def __init__(self, in_channels: int, out_features: int, base_channels: int = 16):\n",
        "      super(Encoder, self).__init__()\n",
        "      self.layer1 = ConvBNReLU(in_channels, base_channels, pooling=False) # Output: (bc, 480, 720)\n",
        "      self.layer2 = ConvBNReLU(base_channels, base_channels * 2, pooling=True) # Output: (bc * 2, 240, 360)\n",
        "\n",
        "      self.layer3 = ConvBNReLU(base_channels * 2, base_channels * 4, pooling=False) # Output: (bc * 4, 240, 360)\n",
        "      self.layer4 = ConvBNReLU(base_channels * 4, base_channels * 8, pooling=True) # Output: (bc * 8, 120, 180)\n",
        "\n",
        "      self.adaptive_pool = nn.AdaptiveAvgPool2d((8, 8))  # Output: (bc, 8, 8)\n",
        "      self.fc = nn.Linear(8 * 8 * base_channels * 8, out_features)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "      x = self.layer1(x)\n",
        "      x = self.layer2(x)\n",
        "      x = self.layer3(x)\n",
        "      x = self.layer4(x)\n",
        "      x = self.adaptive_pool(x)\n",
        "      x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "      x = self.fc(x)\n",
        "      return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, out_features: int, base_channels: int = 16):\n",
        "      super(Decoder, self).__init__()\n",
        "      self.base_channels = base_channels\n",
        "      self.fc = nn.Linear(out_features, 8 * 8 * base_channels * 8) # Match the Encoder output size\n",
        "\n",
        "      self.layer4 = BNReLUConv(base_channels * 8, base_channels * 4, upsampling=True) # Output: (bc * 4, 480, 720)\n",
        "      self.layer3 = BNReLUConv(base_channels * 4, base_channels * 2, upsampling=False) # Output: (bc * 2, 480, 720)\n",
        "\n",
        "      self.layer2 = BNReLUConv(base_channels * 2, base_channels, upsampling=True) # Output: (bc, 480, 720)\n",
        "      self.layer1 = BNReLUConv(base_channels, 3, upsampling=False) # Output: (3, 480, 720)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "      x = self.fc(x)\n",
        "      x = x.view(x.size(0), self.base_channels * 8, 8, 8)  # Reshape to match the start of the decoder convolutional layers\n",
        "      x = self.layer4(x)\n",
        "      x = self.layer3(x)\n",
        "      x = self.layer2(x)\n",
        "      # For the last layer, since we removed upsampling, we need to resize\n",
        "      # the output to the original image size (480, 720).\n",
        "      x = self.layer1(x)\n",
        "      x = torch.nn.functional.interpolate(x, size=(480, 720), mode='nearest') # Resize to original size\n",
        "      x = torch.sigmoid(x)\n",
        "      return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_features: int, base_channels: int = 16):\n",
        "        super(Generator, self).__init__()\n",
        "        self.encoder = Encoder(in_channels=3, out_features=in_features, base_channels=base_channels)\n",
        "        self.decoder = Decoder(in_features, base_channels)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        z = self.encoder(x)\n",
        "        return self.decoder(z)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, base_channels: int = 16):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.classifier = Encoder(in_channels=6, out_features=1, base_channels=base_channels)\n",
        "\n",
        "\n",
        "    def forward(self, rainy_img: torch.Tensor, clean_or_fake: torch.Tensor) -> torch.Tensor:\n",
        "        # Concatenate the rainy image and the clean/fake image along the channel dimension\n",
        "        combined_input = torch.cat([rainy_img, clean_or_fake], dim=1)\n",
        "        # Pass the concatenated input to the classifier\n",
        "        out = self.classifier(combined_input)\n",
        "        return torch.sigmoid(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLfOcpg8Dk66"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xkn2QzBDmN8"
      },
      "outputs": [],
      "source": [
        "def train_conditional_GAN(gen, disc, train_loader, optimizer_gen, optimizer_disc,\n",
        "                          num_epochs=10, device='cuda', model_name='derain_gan'):\n",
        "\n",
        "    gen.to(device).train()\n",
        "    disc.to(device).train()\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    losses_list = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, images in enumerate(train_loader):\n",
        "            real_images, rainy_images = images['gt'].to(device), images['data'].to(device)\n",
        "            batch_size = real_images.size(0)\n",
        "\n",
        "            valid = torch.ones(batch_size, 1).to(device)\n",
        "            fake = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "            # === Train Generator ===\n",
        "            optimizer_gen.zero_grad()\n",
        "            fake_images = gen(rainy_images)\n",
        "            pred_fake = disc(rainy_images, fake_images)\n",
        "            loss_gen = criterion(pred_fake, valid)  # Want D to believe G's output is real\n",
        "            loss_gen.backward()\n",
        "            optimizer_gen.step()\n",
        "\n",
        "            # === Train Discriminator ===\n",
        "            optimizer_disc.zero_grad()\n",
        "            pred_real = disc(rainy_images, real_images)\n",
        "            pred_fake = disc(rainy_images, fake_images.detach())\n",
        "            loss_real = criterion(pred_real, valid)\n",
        "            loss_fake = criterion(pred_fake, fake)\n",
        "            loss_disc = (loss_real + loss_fake) / 2\n",
        "            loss_disc.backward()\n",
        "            optimizer_disc.step()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss_G: {loss_gen.item():.4f}, Loss_D: {loss_disc.item():.4f}')\n",
        "        torch.save(gen.state_dict(), f\"{results_path}/{model_name}\")\n",
        "        losses_list.append((loss_gen.item(), loss_disc.item()))\n",
        "\n",
        "    return losses_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ET3N-KlXDqoN"
      },
      "outputs": [],
      "source": [
        "# Define Geneartor and Discriminator networks\n",
        "# # Parameters for training\n",
        "latent_dim = 128\n",
        "base_channels = 32\n",
        "num_epochs = 20\n",
        "learning_rate_generator = 0.001\n",
        "learning_rate_discriminator = 0.0001\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize Generator and Discriminator\n",
        "generator = Generator(in_features=latent_dim, base_channels=base_channels)\n",
        "discriminator = Discriminator(base_channels=base_channels)\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=learning_rate_generator)\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=learning_rate_discriminator)\n",
        "\n",
        "# Start training\n",
        "losses = train_conditional_GAN(generator, discriminator, train_loader, optimizer_G, optimizer_D, num_epochs, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88z_-PN3Ds0I"
      },
      "source": [
        "Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etLK_TIPDt0D"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Extract generator and discriminator losses\n",
        "gen_losses = [loss[0] for loss in losses]\n",
        "disc_losses = [loss[1] for loss in losses]\n",
        "epochs = range(1, num_epochs + 1)\n",
        "\n",
        "# Plot the losses\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs, gen_losses, label='Generator Loss')\n",
        "plt.plot(epochs, disc_losses, label='Discriminator Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Generator and Discriminator Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(results_path + 'plots' + 'losses.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TS2wxJ9DwA7"
      },
      "outputs": [],
      "source": [
        "def show_generated_images_from_dataset(generator, dataset, device='cpu', n_images=4):\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(n_images):\n",
        "            sample = dataset[i]\n",
        "            rainy = sample['data'].unsqueeze(0).to(device)  # [1, 3, H, W]\n",
        "            fake_clean = generator(rainy).cpu().squeeze(0)  # [3, H, W]\n",
        "\n",
        "            # Mostrar imagen original y generada lado a lado\n",
        "            fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
        "            axs[0].imshow(sample['data'].permute(1, 2, 0))\n",
        "            axs[0].set_title('Imagen con lluvia')\n",
        "            axs[0].axis('off')\n",
        "\n",
        "            axs[1].imshow(fake_clean.permute(1, 2, 0))\n",
        "            axs[1].set_title('Imagen generada (limpia)')\n",
        "            axs[1].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(results_path + f'images' + f'generated_image_model1_{i}.png')\n",
        "            plt.show()\n",
        "\n",
        "show_generated_images_from_dataset(generator, test_a_dataset, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvjQyaCrD-iA"
      },
      "source": [
        "# Second Experiement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTBrSs2AEFFB"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96GI8Ng5Oah6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import tqdm\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------------------- GENERADOR UNET ----------------------\n",
        "class UNetDown(nn.Module):\n",
        "    def __init__(self, in_size, out_size, normalize=True, dropout=0.0):\n",
        "        super().__init__()\n",
        "        layers = [nn.Conv2d(in_size, out_size, 4, 2, 1, bias=False)]\n",
        "        if normalize:\n",
        "            layers.append(nn.BatchNorm2d(out_size))\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        if dropout:\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, in_size, out_size, dropout=0.0):\n",
        "        super().__init__()\n",
        "        layers = [\n",
        "            nn.ConvTranspose2d(in_size, out_size, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_size),\n",
        "            nn.ReLU(inplace=True),\n",
        "        ]\n",
        "        if dropout:\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, skip_input):\n",
        "        x = self.model(x)\n",
        "        return torch.cat((x, skip_input), 1)\n",
        "\n",
        "class GeneratorUNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3):\n",
        "        super().__init__()\n",
        "        self.down1 = UNetDown(in_channels, 64, normalize=False)\n",
        "        self.down2 = UNetDown(64, 128)\n",
        "        self.down3 = UNetDown(128, 256)\n",
        "        self.down4 = UNetDown(256, 512, dropout=0.5)\n",
        "        self.down5 = UNetDown(512, 512, dropout=0.5)\n",
        "        self.down6 = UNetDown(512, 512, dropout=0.5)\n",
        "\n",
        "        self.up1 = UNetUp(512, 512, dropout=0.5)\n",
        "        self.up2 = UNetUp(1024, 512, dropout=0.5)\n",
        "        self.up3 = UNetUp(1024, 256)\n",
        "        self.up4 = UNetUp(512, 128)\n",
        "        self.up5 = UNetUp(256, 64)\n",
        "\n",
        "        self.final = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, out_channels, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        d1 = self.down1(x)\n",
        "        d2 = self.down2(d1)\n",
        "        d3 = self.down3(d2)\n",
        "        d4 = self.down4(d3)\n",
        "        d5 = self.down5(d4)\n",
        "        d6 = self.down6(d5)\n",
        "\n",
        "        u1 = self.up1(d6, d5)\n",
        "        u2 = self.up2(u1, d4)\n",
        "        u3 = self.up3(u2, d3)\n",
        "        u4 = self.up4(u3, d2)\n",
        "        u5 = self.up5(u4, d1)\n",
        "\n",
        "        return self.final(u5)\n",
        "\n",
        "# ---------------------- DISCRIMINADOR PATCHGAN ----------------------\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=6):\n",
        "        super().__init__()\n",
        "        def block(in_c, out_c, norm=True):\n",
        "            layers = [nn.Conv2d(in_c, out_c, 4, 2, 1)]\n",
        "            if norm:\n",
        "                layers.append(nn.BatchNorm2d(out_c))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(in_channels, 64, norm=False),\n",
        "            *block(64, 128),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            nn.Conv2d(512, 1, 4, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img_A, img_B):\n",
        "        x = torch.cat((img_A, img_B), dim=1)\n",
        "        return self.model(x)\n",
        "\n",
        "# ---------------------- TRANSFORMACIONES Y DATASET ----------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Asume que ya definiste RaindropDataset y data_path correctamente\n",
        "train_dataset = RaindropDataset(root_dir=data_path, mode='train', transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "# ---------------------- ENTRENAMIENTO ----------------------\n",
        "\n",
        "g_losses = []\n",
        "d_losses = []\n",
        "l1_losses = []\n",
        "psnr_list = []\n",
        "\n",
        "\n",
        "num_epochs = 100\n",
        "lr = 0.0002\n",
        "lambda_l1 = 100\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Modelos\n",
        "gen = GeneratorUNet().to(device)\n",
        "disc = Discriminator().to(device)\n",
        "\n",
        "# Optimizers y criterios\n",
        "optimizer_G = torch.optim.Adam(gen.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D = torch.optim.Adam(disc.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "criterion_GAN = nn.BCEWithLogitsLoss()\n",
        "criterion_L1 = nn.L1Loss()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    gen.train()  # Set generator to training mode\n",
        "    disc.train()  # Set discriminator to training mode\n",
        "\n",
        "    # Initialize epoch metrics\n",
        "    epoch_g_loss = 0\n",
        "    epoch_d_loss = 0\n",
        "    epoch_l1_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    # Progress bar for batches\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
        "\n",
        "    for batch in loop:\n",
        "        real_rain = batch['data'].to(device)  # Input images with raindrops\n",
        "        real_clean = batch['gt'].to(device)  # Ground truth clean images\n",
        "\n",
        "        # Get shape for creating real/fake labels\n",
        "        with torch.no_grad():\n",
        "            pred_shape = disc(real_rain, real_clean).shape\n",
        "\n",
        "        # Create labels (1 for real, 0 for fake)\n",
        "        valid = torch.ones(pred_shape, device=device)\n",
        "        fake = torch.zeros(pred_shape, device=device)\n",
        "\n",
        "        # ----------------------\n",
        "        # Train Generator\n",
        "        # ----------------------\n",
        "        optimizer_G.zero_grad()  # Clear generator gradients\n",
        "\n",
        "        # Generate fake clean images\n",
        "        fake_clean = gen(real_rain)\n",
        "\n",
        "        # Discriminator's evaluation of fake images\n",
        "        pred_fake = disc(real_rain, fake_clean)\n",
        "\n",
        "        # Calculate losses\n",
        "        loss_GAN = criterion_GAN(pred_fake, valid)  # GAN loss (tries to fool discriminator)\n",
        "        loss_L1 = criterion_L1(fake_clean, real_clean)  # L1 loss (encourages pixel-wise similarity)\n",
        "        loss_G = loss_GAN + lambda_l1 * loss_L1  # Total generator loss\n",
        "\n",
        "        # Backpropagate and update generator\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ----------------------\n",
        "        # Train Discriminator\n",
        "        # ----------------------\n",
        "        optimizer_D.zero_grad()  # Clear discriminator gradients\n",
        "\n",
        "        # Discriminator's evaluation of real images\n",
        "        pred_real = disc(real_rain, real_clean)\n",
        "        loss_real = criterion_GAN(pred_real, valid)  # Loss for real images\n",
        "\n",
        "        # Discriminator's evaluation of fake images (detached from generator)\n",
        "        pred_fake = disc(real_rain, fake_clean.detach())\n",
        "        loss_fake = criterion_GAN(pred_fake, fake)  # Loss for fake images\n",
        "\n",
        "        # Total discriminator loss\n",
        "        loss_D = 0.5 * (loss_real + loss_fake)\n",
        "\n",
        "        # Backpropagate and update discriminator\n",
        "        loss_D.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Update epoch metrics\n",
        "        epoch_g_loss += loss_G.item()\n",
        "        epoch_d_loss += loss_D.item()\n",
        "        epoch_l1_loss += loss_L1.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    # Store average losses for the epoch\n",
        "    g_losses.append(epoch_g_loss / num_batches)\n",
        "    d_losses.append(epoch_d_loss / num_batches)\n",
        "    l1_losses.append(epoch_l1_loss / num_batches)\n",
        "\n",
        "    # Calculate PSNR on sample images\n",
        "    gen.eval()  # Set generator to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        psnr_total = 0\n",
        "        samples = 50  # Number of samples to evaluate\n",
        "\n",
        "        for i in range(samples):\n",
        "            sample = train_dataset[i]  # Get sample\n",
        "            input_img = sample['data'].unsqueeze(0).to(device)  # Add batch dimension\n",
        "            target_img = sample['gt'].permute(1, 2, 0).cpu().numpy()  # Prepare ground truth\n",
        "            output_img = gen(input_img).squeeze(0).permute(1, 2, 0).clamp(0, 1).cpu().numpy()  # Generate output\n",
        "            psnr_total += psnr(target_img, output_img, data_range=1.0)  # Calculate PSNR\n",
        "\n",
        "        psnr_avg = psnr_total / samples  # Average PSNR\n",
        "        psnr_list.append(psnr_avg)  # Store PSNR\n",
        "        print(f\"Epoch {epoch+1}: PSNR = {psnr_avg:.2f} dB\")  # Print PSNR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeDDEIH_EHzA"
      },
      "source": [
        "Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1XbgO8rEIrR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_generated_images_from_dataset(generator, dataset, device='cpu', n_images=4):\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(n_images):\n",
        "            sample = dataset[i]\n",
        "            rainy = sample['data'].unsqueeze(0).to(device)  # [1, 3, H, W]\n",
        "            fake_clean = generator(rainy).cpu().squeeze(0)  # [3, H, W]\n",
        "\n",
        "            # Clipping (por seguridad)\n",
        "            rainy_img = sample['data'].clamp(0, 1).permute(1, 2, 0).cpu().numpy()\n",
        "            fake_img = fake_clean.clamp(0, 1).permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "            # Mostrar imagen original y generada lado a lado\n",
        "            fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
        "            axs[0].imshow(rainy_img)\n",
        "            axs[0].set_title('Imagen con lluvia')\n",
        "            axs[0].axis('off')\n",
        "\n",
        "            axs[1].imshow(fake_img)\n",
        "            axs[1].set_title('Imagen generada (limpia)')\n",
        "            axs[1].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "show_generated_images_from_dataset(gen, train_dataset, device=device, n_images=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFC4aIdsOpjj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(g_losses, label='Generator Loss')\n",
        "plt.plot(d_losses, label='Discriminator Loss')\n",
        "plt.plot(l1_losses, label='L1 Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Pérdidas por Epoch')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{results_path}/losses.png\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(psnr_list, label='PSNR', color='purple')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('PSNR (dB)')\n",
        "plt.title('PSNR por Epoch')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{results_path}/psnr.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOZnnAEDOrWC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "def show_generated_images_with_patch_confidence(generator, discriminator, dataset, device='cpu', n_images=4):\n",
        "    generator.eval()\n",
        "    discriminator.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(n_images):\n",
        "            sample = dataset[i]\n",
        "            rainy = sample['data'].unsqueeze(0).to(device)\n",
        "            fake_clean = generator(rainy)\n",
        "\n",
        "            # Obtener matriz de confianza del discriminador\n",
        "            patch_output = torch.sigmoid(discriminator(rainy, fake_clean)).squeeze().cpu().numpy()\n",
        "\n",
        "            # Procesar imágenes para visualización\n",
        "            rainy_img = sample['data'].clamp(0, 1).permute(1, 2, 0).cpu().numpy()\n",
        "            fake_img = fake_clean.squeeze(0).clamp(0, 1).permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "            # Mostrar imágenes y matriz\n",
        "            fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
        "            axs[0].imshow(rainy_img)\n",
        "            axs[0].set_title('Imagen con lluvia')\n",
        "            axs[0].axis('off')\n",
        "\n",
        "            axs[1].imshow(fake_img)\n",
        "            axs[1].set_title('Imagen generada (limpia)')\n",
        "            axs[1].axis('off')\n",
        "\n",
        "            im = axs[2].imshow(patch_output, cmap='viridis', vmin=0, vmax=1)\n",
        "            axs[2].set_title('Confianza por patch (PatchGAN)')\n",
        "            axs[2].axis('off')\n",
        "            plt.colorbar(im, ax=axs[2], shrink=0.7)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "show_generated_images_with_patch_confidence(gen, disc, train_dataset, device=device, n_images=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTSGq6p2DiJQ"
      },
      "source": [
        "# Third Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwm357z7JjmZ"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQBYYrsOJK7_"
      },
      "outputs": [],
      "source": [
        "# ---------------------- GENERADOR UNET ----------------------\n",
        "class UNetDown(nn.Module):\n",
        "    def __init__(self, in_size, out_size, normalize=True, dropout=0.0):\n",
        "        super().__init__()\n",
        "        layers = [nn.Conv2d(in_size, out_size, 4, 2, 1, bias=False)]\n",
        "        if normalize:\n",
        "            layers.append(nn.BatchNorm2d(out_size))\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        if dropout:\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, in_size, out_size, dropout=0.0):\n",
        "        super().__init__()\n",
        "        layers = [\n",
        "            nn.ConvTranspose2d(in_size, out_size, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_size),\n",
        "            nn.ReLU(inplace=True),\n",
        "        ]\n",
        "        if dropout:\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, skip_input):\n",
        "        x = self.model(x)\n",
        "        return torch.cat((x, skip_input), 1)\n",
        "\n",
        "class GeneratorUNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3):\n",
        "        super().__init__()\n",
        "        self.down1 = UNetDown(in_channels, 64, normalize=False)\n",
        "        self.down2 = UNetDown(64, 128)\n",
        "        self.down3 = UNetDown(128, 256)\n",
        "        self.down4 = UNetDown(256, 512, dropout=0.5)\n",
        "        self.down5 = UNetDown(512, 512, dropout=0.5)\n",
        "        self.down6 = UNetDown(512, 512, dropout=0.5)\n",
        "\n",
        "        self.up1 = UNetUp(512, 512, dropout=0.5)\n",
        "        self.up2 = UNetUp(1024, 512, dropout=0.5)\n",
        "        self.up3 = UNetUp(1024, 256)\n",
        "        self.up4 = UNetUp(512, 128)\n",
        "        self.up5 = UNetUp(256, 64)\n",
        "\n",
        "        self.final = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, out_channels, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        d1 = self.down1(x)\n",
        "        d2 = self.down2(d1)\n",
        "        d3 = self.down3(d2)\n",
        "        d4 = self.down4(d3)\n",
        "        d5 = self.down5(d4)\n",
        "        d6 = self.down6(d5)\n",
        "\n",
        "        u1 = self.up1(d6, d5)\n",
        "        u2 = self.up2(u1, d4)\n",
        "        u3 = self.up3(u2, d3)\n",
        "        u4 = self.up4(u3, d2)\n",
        "        u5 = self.up5(u4, d1)\n",
        "\n",
        "        return self.final(u5)\n",
        "\n",
        "# ---------------------- DISCRIMINADOR PATCHGAN ----------------------\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=6):\n",
        "        super().__init__()\n",
        "        def block(in_c, out_c, norm=True):\n",
        "            layers = [nn.Conv2d(in_c, out_c, 4, 2, 1)]\n",
        "            if norm:\n",
        "                layers.append(nn.BatchNorm2d(out_c))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(in_channels, 64, norm=False),\n",
        "            *block(64, 128),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            nn.Conv2d(512, 1, 4, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img_A, img_B):\n",
        "        x = torch.cat((img_A, img_B), dim=1)\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDBmeX3lJtCP"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APbg9wA0Jrrf"
      },
      "outputs": [],
      "source": [
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "\n",
        "def train_GAN(gen, disc, train_loader, optimizer_G, optimizer_D, num_epochs=10,\n",
        "              lambda_l1=100, device=\"cuda\", name='more_stable_CGAN'):\n",
        "\n",
        "    # Initializing the lists to track metrics\n",
        "    losses_list = []  # Will store (generator_loss, discriminator_loss) for each epoch\n",
        "    dic_accuracies_list = []  # Will store discriminator accuracy for each epoch\n",
        "    psnr_list = []  # Will store PSNR values for each epoch\n",
        "\n",
        "    # Loss functions\n",
        "    criterion_GAN = nn.BCEWithLogitsLoss()\n",
        "    criterion_L1 = nn.L1Loss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        gen.train()\n",
        "        disc.train()\n",
        "\n",
        "        # Initialize epoch metrics\n",
        "        epoch_g_loss = 0\n",
        "        epoch_d_loss = 0\n",
        "        epoch_l1_loss = 0\n",
        "        running_corrects = 0\n",
        "        total_preds = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        # Progress bar for batches\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
        "\n",
        "        for batch in loop:\n",
        "            real_rain = batch['data'].to(device)\n",
        "            real_clean = batch['gt'].to(device)\n",
        "\n",
        "            # Get shape for creating real/fake labels\n",
        "            with torch.no_grad():\n",
        "                pred_shape = disc(real_rain, real_clean).shape\n",
        "\n",
        "            # Label smoothing: using 0.9 for real and 0.1 for fake\n",
        "            valid = torch.full(pred_shape, 0.9, device=device)\n",
        "            fake = torch.full(pred_shape, 0.1, device=device)\n",
        "\n",
        "            # -----------------\n",
        "            # Train Generator\n",
        "            # -----------------\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            # Generate fake clean images\n",
        "            fake_clean = gen(real_rain)\n",
        "\n",
        "            # Discriminator's evaluation of fake images\n",
        "            pred_fake = disc(real_rain, fake_clean)\n",
        "\n",
        "            # Calculate losses\n",
        "            loss_GAN = criterion_GAN(pred_fake, valid)\n",
        "            loss_L1 = criterion_L1(fake_clean, real_clean)\n",
        "            loss_G = loss_GAN + lambda_l1 * loss_L1\n",
        "\n",
        "            # Backpropagate and update generator\n",
        "            loss_G.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            # ---------------------\n",
        "            # Train Discriminator\n",
        "            # ---------------------\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            # Discriminator's evaluation of real images\n",
        "            pred_real = disc(real_rain, real_clean)\n",
        "            loss_real = criterion_GAN(pred_real, valid)\n",
        "\n",
        "            # Discriminator's evaluation of fake images (detached from generator)\n",
        "            pred_fake = disc(real_rain, fake_clean.detach())\n",
        "            loss_fake = criterion_GAN(pred_fake, fake)\n",
        "\n",
        "            # Total discriminator loss\n",
        "            loss_D = 0.5 * (loss_real + loss_fake)\n",
        "\n",
        "            # Backpropagate and update discriminator\n",
        "            loss_D.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # Update epoch metrics\n",
        "            epoch_g_loss += loss_G.item()\n",
        "            epoch_d_loss += loss_D.item()\n",
        "            epoch_l1_loss += loss_L1.item()\n",
        "            num_batches += 1\n",
        "\n",
        "            # Calculate discriminator accuracy\n",
        "            with torch.no_grad():\n",
        "                pred_real_class = (torch.sigmoid(pred_real) > 0.5).float()\n",
        "                pred_fake_class = (torch.sigmoid(pred_fake) <= 0.5).float()\n",
        "\n",
        "                correct_real = (pred_real_class == 1).float().sum()\n",
        "                correct_fake = (pred_fake_class == 1).float().sum()\n",
        "\n",
        "                running_corrects += correct_real + correct_fake\n",
        "                total_preds += pred_real.numel() + pred_fake.numel()\n",
        "\n",
        "            loop.set_postfix({\n",
        "                \"G_loss\": f\"{loss_G.item():.4f}\",\n",
        "                \"D_loss\": f\"{loss_D.item():.4f}\",\n",
        "                \"D_acc\": f\"{100 * running_corrects.item() / total_preds:.2f}%\"\n",
        "            })\n",
        "\n",
        "        # Calculate average metrics for the epoch\n",
        "        avg_g_loss = epoch_g_loss / num_batches\n",
        "        avg_d_loss = epoch_d_loss / num_batches\n",
        "        epoch_accuracy = 100 * running_corrects.item() / total_preds\n",
        "\n",
        "        # Calculate PSNR on validation samples\n",
        "        gen.eval()\n",
        "        with torch.no_grad():\n",
        "            psnr_total = 0\n",
        "            samples = min(50, len(train_loader.dataset))  # Use up to 50 samples\n",
        "            for i in range(samples):\n",
        "                sample = train_loader.dataset[i]\n",
        "                input_img = sample['data'].unsqueeze(0).to(device)\n",
        "                target_img = sample['gt'].permute(1, 2, 0).cpu().numpy()\n",
        "                output_img = gen(input_img).squeeze(0).permute(1, 2, 0).clamp(0, 1).cpu().numpy()\n",
        "                psnr_total += psnr(target_img, output_img, data_range=1.0)\n",
        "            psnr_avg = psnr_total / samples\n",
        "            psnr_list.append(psnr_avg)\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs} | \"\n",
        "              f\"G_loss: {avg_g_loss:.4f} | D_loss: {avg_d_loss:.4f} | \"\n",
        "              f\"D_acc: {epoch_accuracy:.2f}% | PSNR: {psnr_avg:.2f} dB\")\n",
        "\n",
        "        # Store metrics\n",
        "        losses_list.append((avg_g_loss, avg_d_loss))\n",
        "        dic_accuracies_list.append(epoch_accuracy)\n",
        "\n",
        "        # Save model checkpoints periodically\n",
        "        if (epoch + 1) % 10 == 0 or epoch == num_epochs - 1:\n",
        "            torch.save(gen.state_dict(), f\"{name}_gen_epoch{epoch+1}.pth\")\n",
        "            torch.save(disc.state_dict(), f\"{name}_disc_epoch{epoch+1}.pth\")\n",
        "\n",
        "    return losses_list, dic_accuracies_list, psnr_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0bjUlVpJzmz"
      },
      "outputs": [],
      "source": [
        "num_epochs = 100\n",
        "gen_lr = 5e-4\n",
        "dic_lr = 2e-4\n",
        "\n",
        "lambda_l1 = 100\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Modelos\n",
        "gen = GeneratorUNet().to(device)\n",
        "disc = Discriminator().to(device)\n",
        "\n",
        "# Optimizers y criterios\n",
        "optimizer_G = torch.optim.Adam(gen.parameters(), lr=gen_lr, betas=(0.7, 0.999))\n",
        "optimizer_D = torch.optim.Adam(disc.parameters(), lr=dic_lr, betas=(0.5, 0.999))\n",
        "\n",
        "#trining\n",
        "# Correct the order of arguments in the function call\n",
        "losses, accuracies, psnr = train_GAN(gen, disc, train_loader, optimizer_G, optimizer_D,\n",
        "                                     num_epochs=num_epochs, lambda_l1=lambda_l1, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSfrc-2vEcso"
      },
      "source": [
        "Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULDGbs8CEdyh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_generated_images_from_dataset(generator, dataset, device='cpu', n_images=4, name='comparaciones_disc_mejorado'):\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(n_images):\n",
        "            sample = dataset[i]\n",
        "            rainy = sample['data'].unsqueeze(0).to(device)  # [1, 3, H, W]\n",
        "            fake_clean = generator(rainy).cpu().squeeze(0)  # [3, H, W]\n",
        "\n",
        "            # Clipping (por seguridad)\n",
        "            rainy_img = sample['data'].clamp(0, 1).permute(1, 2, 0).cpu().numpy()\n",
        "            fake_img = fake_clean.clamp(0, 1).permute(1, 2, 0).cpu().numpy()\n",
        "            groud_truth = sample['gt'].permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "            # Mostrar imagen original y generada lado a lado\n",
        "            fig, axs = plt.subplots(1, 3, figsize=(12, 6))\n",
        "            axs[0].imshow(rainy_img)\n",
        "            axs[0].set_title('Imagen con lluvia')\n",
        "            axs[0].axis('off')\n",
        "\n",
        "            axs[1].imshow(fake_img)\n",
        "            axs[1].set_title('Imagen generada (limpia)')\n",
        "            axs[1].axis('off')\n",
        "\n",
        "            axs[2].imshow(rainy_img)\n",
        "            axs[2].imshow(groud_truth)\n",
        "            axs[2].set_title('Ground Truth')\n",
        "            axs[2].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(os.path.join(results_path, 'plots', 'comparaciones_disc_mejorado', name + f'_{i}.png'))\n",
        "            plt.show()\n",
        "\n",
        "show_generated_images_from_dataset(gen, test_a_dataset, device=device, n_images=40, name='comparaciones_disc_mejorado')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wM3tLuhwEnvc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Make two separate plots:\n",
        "# 1. Generator and Discriminator losses over epochs.\n",
        "# 2. PSNR and Discriminator accuracy over epochs.\n",
        "\n",
        "epochs_list = range(1, num_epochs + 1)\n",
        "\n",
        "# Plot 1: Generator and Discriminator Losses\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs_list, [l[0] for l in losses], label='Generator Loss')\n",
        "plt.plot(epochs_list, [l[1] for l in losses], label='Discriminator Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Generator and Discriminator Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(results_path, 'plots', 'losses_plot_improved_disc.png')) # Save plot\n",
        "plt.show()\n",
        "\n",
        "# Plot 2: PSNR and Discriminator Accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs_list, accuracies, label='Discriminator Accuracy (%)', color='tab:red')\n",
        "plt.plot(epochs_list, psnr, label='PSNR (dB)', color='tab:green')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Generator and Discriminator Accuracy over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(results_path, 'plots', 'psnr_disc_accuracy_plot.png')) # Save plot\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "5u4gSMrWJLqF",
        "G-ngfdUaAp7S",
        "tJN-8yWVDM6y",
        "pvjQyaCrD-iA",
        "oTSGq6p2DiJQ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
